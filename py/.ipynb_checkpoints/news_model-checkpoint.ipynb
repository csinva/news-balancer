{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# notes\n",
    "- UCI ML News Aggregator Dataset contains headlines\n",
    "- categories for over 400k news articles.\n",
    "- currently uses multinomial scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get some libraries that will be useful\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)x\n",
    "\n",
    "# the Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# function to split the data for cross-validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "# function for transforming documents into counts\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# function for encoding categories\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# grab the data\n",
    "news = pd.read_csv(\"../data_news_aggregator/news_data_uci.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#news.head() # let's take a look at our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing we'll want to do is normalize the TITLE column a bit: remove punctuation and lowercase everything. This will give us a smaller set of words, which will decrease the size of our model, and ensure that words are treated the same even if they occur capitalized at the beginning of the headline or lowercase in the middle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from train import normalize_text\n",
    "news['TEXT'] = [normalize_text(s) for s in news['TITLE']]\n",
    "#print(len(news['TEXT']),news['TEXT'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "422419\n",
      "29\n"
     ]
    }
   ],
   "source": [
    "print(len(news['STORY']))\n",
    "print(len(news['STORY'][0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_related_article_idxs(x_1, story_1):\n",
    "    idxs = news['STORY'] == story_1\n",
    "    return idxs\n",
    "def get_liberal_idxs(idxs):\n",
    "    pubs = [s.lower() for s in news['PUBLISHER'][idxs]]\n",
    "    idxs_cons = np.zeros((len(idxs),1))\n",
    "    return idxs_cons\n",
    "def get_conservative_idxs(idxs):\n",
    "    pubs = [s.lower() for s in news['PUBLISHER'][idxs]]\n",
    "    return idxs\n",
    "idxs_init = get_related_article_idxs(news['TEXT'][0],news['STORY'][0])\n",
    "idxs_liberal = get_liberal_idxs(idxs_init)\n",
    "idxs_conservative = get_conservative_idxs(idxs_init)\n",
    "idxs_fair = np.logical_and(idxs_init,np.logical_not(np.logical_or(idxs_liberal,idxs_conservative)))\n",
    "print(\"sums\",np.sum(idxs_init),np.sum(idxs_liberal),np.sum(idxs_conservative),np.sum(idxs_fair))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pubs=news['PUBLISHER']\n",
    "#myset = set(pubs)\n",
    "#print(myset)\n",
    "#pubs = np.array(pubs,dtype=\"str\")\n",
    "#x = np.unique(pubs,return_counts=True)\n",
    "#print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# format into matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(337935, 54637)\n",
      "(337935,)\n",
      "(84484, 54637)\n",
      "(84484,)\n"
     ]
    }
   ],
   "source": [
    "# pull the data into vectors\n",
    "vectorizer = CountVectorizer()\n",
    "x = vectorizer.fit_transform(news['TEXT'])\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(news['CATEGORY'])\n",
    "\n",
    "# split into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# take a look at the shape of each of these\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the x training vector contains 337935 observations of 54637 occurrences -- this latter number is the number of unique words in the entire collection of headlines. The x training vector contains the 337935 labels associated with each observation in the x training vector.\n",
    "\n",
    "So we're ready to go. Let's make the classifier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How well did it do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92754841153354484"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you feel like exploring what words are characteristic of each category, you can pull out the coefficients of the Naive Bayes classifier:"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 583,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
