{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e45fa26c-5b46-d737-6486-2b7f4de1c915"
   },
   "source": [
    "# notes\n",
    "- UCI ML News Aggregator Dataset contains headlines\n",
    "- categories for over 400k news articles.\n",
    "- currently uses multinomial scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "_cell_guid": "a12bb00d-8b76-ef20-38fd-8777b9c10cba",
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get some libraries that will be useful\n",
    "import re\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)x\n",
    "\n",
    "# the Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# function to split the data for cross-validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "# function for transforming documents into counts\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# function for encoding categories\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# grab the data\n",
    "news = pd.read_csv(\"../data_news_aggregator/news_data_uci.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "0db96719-79c5-b270-a349-ed9723f8b838",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>TITLE</th>\n",
       "      <th>URL</th>\n",
       "      <th>PUBLISHER</th>\n",
       "      <th>CATEGORY</th>\n",
       "      <th>STORY</th>\n",
       "      <th>HOSTNAME</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Fed official says weak data caused by weather,...</td>\n",
       "      <td>http://www.latimes.com/business/money/la-fi-mo...</td>\n",
       "      <td>Los Angeles Times</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.latimes.com</td>\n",
       "      <td>1394470370698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Fed's Charles Plosser sees high bar for change...</td>\n",
       "      <td>http://www.livemint.com/Politics/H2EvwJSK2VE6O...</td>\n",
       "      <td>Livemint</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.livemint.com</td>\n",
       "      <td>1394470371207</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>US open: Stocks fall after Fed official hints ...</td>\n",
       "      <td>http://www.ifamagazine.com/news/us-open-stocks...</td>\n",
       "      <td>IFA Magazine</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.ifamagazine.com</td>\n",
       "      <td>1394470371550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Fed risks falling 'behind the curve', Charles ...</td>\n",
       "      <td>http://www.ifamagazine.com/news/fed-risks-fall...</td>\n",
       "      <td>IFA Magazine</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.ifamagazine.com</td>\n",
       "      <td>1394470371793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Fed's Plosser: Nasty Weather Has Curbed Job Gr...</td>\n",
       "      <td>http://www.moneynews.com/Economy/federal-reser...</td>\n",
       "      <td>Moneynews</td>\n",
       "      <td>b</td>\n",
       "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
       "      <td>www.moneynews.com</td>\n",
       "      <td>1394470372027</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                              TITLE  \\\n",
       "0   1  Fed official says weak data caused by weather,...   \n",
       "1   2  Fed's Charles Plosser sees high bar for change...   \n",
       "2   3  US open: Stocks fall after Fed official hints ...   \n",
       "3   4  Fed risks falling 'behind the curve', Charles ...   \n",
       "4   5  Fed's Plosser: Nasty Weather Has Curbed Job Gr...   \n",
       "\n",
       "                                                 URL          PUBLISHER  \\\n",
       "0  http://www.latimes.com/business/money/la-fi-mo...  Los Angeles Times   \n",
       "1  http://www.livemint.com/Politics/H2EvwJSK2VE6O...           Livemint   \n",
       "2  http://www.ifamagazine.com/news/us-open-stocks...       IFA Magazine   \n",
       "3  http://www.ifamagazine.com/news/fed-risks-fall...       IFA Magazine   \n",
       "4  http://www.moneynews.com/Economy/federal-reser...          Moneynews   \n",
       "\n",
       "  CATEGORY                          STORY             HOSTNAME      TIMESTAMP  \n",
       "0        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM      www.latimes.com  1394470370698  \n",
       "1        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM     www.livemint.com  1394470371207  \n",
       "2        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM  www.ifamagazine.com  1394470371550  \n",
       "3        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM  www.ifamagazine.com  1394470371793  \n",
       "4        b  ddUyU0VZz0BRneMioxUPQVP6sIxvM    www.moneynews.com  1394470372027  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news.head() # let's take a look at our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "85c96bd1-f6ac-99c5-383d-8f6e84f9093e"
   },
   "source": [
    "One thing we'll want to do is normalize the TITLE column a bit: remove punctuation and lowercase everything. This will give us a smaller set of words, which will decrease the size of our model, and ensure that words are treated the same even if they occur capitalized at the beginning of the headline or lowercase in the middle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "0e2df6cf-eee7-0e5c-9000-bf624af694fa",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def normalize_text(s):\n",
    "    s = s.lower()\n",
    "    \n",
    "    # remove punctuation that is not word-internal (e.g., hyphens, apostrophes)\n",
    "    s = re.sub('\\s\\W',' ',s)\n",
    "    s = re.sub('\\W\\s',' ',s)\n",
    "    \n",
    "    # make sure we didn't introduce any double spaces\n",
    "    s = re.sub('\\s+',' ',s)\n",
    "    \n",
    "    return s\n",
    "\n",
    "news['TEXT'] = [normalize_text(s) for s in news['TITLE']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "2850722b-ed92-ef0b-04c9-84841b2b0512"
   },
   "source": [
    "# format into matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "_cell_guid": "20de11e1-fddb-288f-de82-8a9cc15d9338",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(337935, 54637)\n",
      "(337935,)\n",
      "(84484, 54637)\n",
      "(84484,)\n"
     ]
    }
   ],
   "source": [
    "# pull the data into vectors\n",
    "vectorizer = CountVectorizer()\n",
    "x = vectorizer.fit_transform(news['TEXT'])\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(news['CATEGORY'])\n",
    "\n",
    "# split into train and test sets\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# take a look at the shape of each of these\n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "bd9d43dd-c7c6-47ab-0c15-6dd14b495b93"
   },
   "source": [
    "So the x training vector contains 337935 observations of 54637 occurrences -- this latter number is the number of unique words in the entire collection of headlines. The x training vector contains the 337935 labels associated with each observation in the x training vector.\n",
    "\n",
    "So we're ready to go. Let's make the classifier!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "_cell_guid": "971e7969-766c-e75b-4ae8-b09ce26b33df",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "e77ee291-1443-22fd-0f31-4405a4b271d1"
   },
   "source": [
    "How well did it do?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "_cell_guid": "62a469f2-6ac6-c5c5-a0c2-ccbd3e97489d",
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92754841153354484"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb.score(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "4a02a410-2b9e-ee03-71d4-64770b47d161"
   },
   "source": [
    "If you feel like exploring what words are characteristic of each category, you can pull out the coefficients of the Naive Bayes classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "05f9d835-3c91-d134-0462-b53ed30597ff",
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4, 54637)\n",
      "[[ -8.72924117 -11.46649053 -13.6637151  ..., -13.6637151  -13.6637151\n",
      "  -13.6637151 ]\n",
      " [-11.22364378 -12.05032235 -13.9962325  ..., -12.20447303 -12.20447303\n",
      "  -13.9962325 ]\n",
      " [-10.3346529  -10.8736494  -12.81955955 ..., -12.12641236 -12.12641236\n",
      "  -12.81955955]\n",
      " [-10.23438835 -11.33300063 -13.63558573 ..., -12.53697344 -12.53697344\n",
      "  -12.94243855]]\n"
     ]
    }
   ],
   "source": [
    "coefs = nb.coef_\n",
    "print(coefs.shape)\n",
    "print(coefs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "a2eedc65-df12-f305-a6bb-dd6a949094bb"
   },
   "source": [
    "That's a matrix of the log probability of each word given each category. The usual way to find characteristic words for a category is to take those words with the largest log odds ratio per category, which is an exercise left to the reader.\n",
    "\n",
    "The coefficients only give you log probabilities by index (which corresponds to whatever ordering the CountVectorizer decided on). To convert these indices back to words, you can pull out the vocabulary from the vectorizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "_cell_guid": "425058d7-ca67-6f2f-cb18-8daec419a3d7",
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_reverse_vocabulary(vectorizer):\n",
    "    revvoc = {}\n",
    "\n",
    "    vocab = vectorizer.vocabulary_\n",
    "    for w in vocab:\n",
    "        i = vocab[w]\n",
    "\n",
    "        revvoc[i] = w\n",
    "\n",
    "    return revvoc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "_cell_guid": "0b88bad7-4612-f6a3-0fa4-8861ac2e6974"
   },
   "source": [
    "And you can do something similar with the LabelEncoder to match the model's output classifications back to the dataset's categories. Again, this is left to the reader.\n",
    "\n",
    "I hope this was helpful in learning how to classify text! Possible next steps: \n",
    "- figure out the most characteristic words for each news category (someone please do this and report back!)\n",
    "- figure out how accurately we can classify particular news items (STORY in the dataset) given headline text"
   ]
  }
 ],
 "metadata": {
  "_change_revision": 583,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
