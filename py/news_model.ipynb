{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# notes\n",
    "- UCI ML News Aggregator Dataset contains headlines\n",
    "- categories for over 400k news articles.\n",
    "- currently uses multinomial scikit learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get some libraries that will be useful\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)x\n",
    "\n",
    "# the Naive Bayes model\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# function to split the data for cross-validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "# function for transforming documents into counts\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "# function for encoding categories\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "\n",
    "# grab the data\n",
    "news = pd.read_csv(\"../data_news_aggregator/news_data_uci.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#news.head() # let's take a look at our data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One thing we'll want to do is normalize the TITLE column a bit: remove punctuation and lowercase everything. This will give us a smaller set of words, which will decrease the size of our model, and ensure that words are treated the same even if they occur capitalized at the beginning of the headline or lowercase in the middle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from train import normalize_text\n",
    "news['TEXT'] = [normalize_text(s) for s in news['TITLE']]\n",
    "#print(len(news['TEXT']),news['TEXT'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# format into matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_shape,y_shape (1000, 1816) (1000,)\n"
     ]
    }
   ],
   "source": [
    "# pull the data into vectors\n",
    "tits = news[\"TEXT\"][:1000]\n",
    "stories = news[\"STORY\"][:1000]\n",
    "vectorizer = CountVectorizer()\n",
    "x = vectorizer.fit_transform(tits)\n",
    "\n",
    "encoder = LabelEncoder()\n",
    "y = encoder.fit_transform(stories)\n",
    "\n",
    "print(\"x_shape,y_shape\",x.shape,y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000,)\n",
      "fed official says weak data caused by weather should not slow taper\n",
      "fed's charles plosser sees high bar for change in pace of tapering\n",
      "1816\n"
     ]
    }
   ],
   "source": [
    "print(tits.shape)\n",
    "print(tits[0])\n",
    "print(tits[1])\n",
    "analyze = vectorizer.build_analyzer()\n",
    "voc = set(analyze(tits[0]))\n",
    "for i in range(len(tits)):\n",
    "    voc.update(analyze(tits[i]))\n",
    "print(len(sorted(voc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.97499999999999998"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb = MultinomialNB()\n",
    "nb.fit(x, y)\n",
    "nb.score(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fed official says weak data caused by weather should not slow taper\n",
      "x_1 (1, 1816)\n",
      "y_1 [11] 11 ['ddUyU0VZz0BRneMioxUPQVP6sIxvM']\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(vocabulary=voc)\n",
    "print(tits[0])\n",
    "x_1 = vectorizer.fit_transform([tits[0]])\n",
    "print(\"x_1\",x_1.shape)\n",
    "y_1 = nb.predict(x_1)\n",
    "print(\"y_1\", y_1, y[0],encoder.inverse_transform(y_1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "_change_revision": 583,
  "_is_fork": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
